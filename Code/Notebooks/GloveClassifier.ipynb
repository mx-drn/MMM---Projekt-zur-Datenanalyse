{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "GloveClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR93s9TFix3Y",
        "outputId": "b776c66e-a878-49c8-b1e8-9969e4525c82"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "!pip install gensim\r\n",
        "!pip install nltk"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN4bXH-diwjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1816ab74-64fe-4cc9-afda-3c3f74d32845"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import concatenate\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcvUvHtxjHZa",
        "outputId": "53cf67ed-8335-4043-9dc0-6d51a8131105"
      },
      "source": [
        "# Google TPU einrichten (muss in den Notebook-Einstelllungen aktiviert sein)\r\n",
        "# bei Nichtnutzung einfach die Zeile \"with tpu_strategy.scope():\" l√∂schen\r\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.34.98.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.34.98.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.34.98.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.34.98.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5c_yFyiiwj6"
      },
      "source": [
        "#Dictionary mit allen .json\n",
        "FILES = {1: 'Gangart.json',\n",
        "        2 : 'Vegan.json',\n",
        "        3 : 'Laender.json',\n",
        "        4 : 'Mahlzeit.json'}    "
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlrGHWZDQl-l"
      },
      "source": [
        "CURRENT_FILE = FILES[1]\r\n",
        "\r\n",
        "#Nur Glove (Zubereitungshinweise) verwenden oder √ºber Multiple Input auch die Zutaten?\r\n",
        "BOTH_NEURAL_NETWORKS = False\r\n",
        "\r\n",
        "#Minimale L√§nge aller Directions\r\n",
        "MINLEN_DIRECTIONS = 106\r\n",
        "\r\n",
        "# !hier Pfad angeben, wo die Daten liegen!\r\n",
        "DATA_PATH = 'drive/MyDrive/Colab Notebooks/Data/'"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COH05GPzQovw"
      },
      "source": [
        "#Load Data\r\n",
        "with open(DATA_PATH + CURRENT_FILE) as file:\r\n",
        "    data = json.load(file)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiSjR8Bliwj7"
      },
      "source": [
        "#Directions aufbereiten\n",
        "def preprocess_text(sen):\n",
        "\n",
        "    # Punkte und Zahlen eliminieren\n",
        "    sen = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Einzelne Characters entfernen\n",
        "    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)\n",
        "\n",
        "    # Mehrere Leerzeichen entfernen\n",
        "    sen = re.sub(r'\\s+', ' ', sen)\n",
        "\n",
        "    #Stopwords entfernen\n",
        "    sen = ' '.join(filter(lambda word: word.lower() not in stopwords.words('english'),  sen.split()))\n",
        "\n",
        "    return sen\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sbv1A9Yiwj7"
      },
      "source": [
        "#Input und Output Vektor\n",
        "inputData = []\n",
        "labels = []\n",
        "\n",
        "#Dictionaries\n",
        "index_Kategorien = dict()\n",
        "index_Zutaten = dict()\n",
        "\n",
        "#Create Dict for Ingredients and Categories and Ditections with index as value\n",
        "def createDict():\n",
        "    #Categories and Ingredients\n",
        "    counterOne = 0\n",
        "    counterTwo = 0\n",
        "    counterThree = 0\n",
        "    for recipe in data:\n",
        "        ingredients = recipe['ingredients']\n",
        "        category = recipe['category']\n",
        "\n",
        "        for ing in ingredients:\n",
        "            if ing not in index_Zutaten:\n",
        "                index_Zutaten[ing] = counterOne\n",
        "                counterOne +=1\n",
        "        \n",
        "        if category not in index_Kategorien:\n",
        "            index_Kategorien[category] = counterTwo\n",
        "            counterTwo +=1 \n",
        "            \n",
        "            \n",
        "    \n",
        "#Create Input Vector and Output Vector (OneHot)\n",
        "def createDataAndLabel():\n",
        "    for recipe in data:\n",
        "        \n",
        "        #Input Vector\n",
        "        ingredients = recipe['ingredients']\n",
        "        category = recipe['category']\n",
        "        anweisungen = recipe['directions_string']\n",
        "        \n",
        "        inputVectorZutaten = np.zeros(len(index_Zutaten))\n",
        "        inputVectorAnweisungen = []\n",
        "        \n",
        "        #InputVector Zutaten\n",
        "        for zutat in ingredients:\n",
        "            if zutat in index_Zutaten:\n",
        "                inputVectorZutaten[index_Zutaten[zutat]] = 1\n",
        "        \n",
        "        inputData.append([inputVectorZutaten,preprocess_text(anweisungen)])\n",
        "                \n",
        "        #Output Vector\n",
        "        outputVector = np.zeros(len(index_Kategorien))\n",
        "        outputVector[index_Kategorien[category]] = 1\n",
        "        labels.append(outputVector)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNvUBOclRREJ"
      },
      "source": [
        "with tpu_strategy.scope():\r\n",
        "  createDict()\r\n",
        "  createDataAndLabel()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5F-uA8iwj9"
      },
      "source": [
        "def splitData():\n",
        "  train_input, test_input, train_label, test_label = train_test_split(inputData, labels, test_size=0.2, random_state=42)\n",
        "  #Input Vektor f√ºr Zutaten und Anweisungen trennen\n",
        "  train_input_zutaten = []\n",
        "  train_input_anweisungen = []\n",
        "  test_input_zutaten = []\n",
        "  test_input_anweisungen = []\n",
        "\n",
        "  for entry in train_input:\n",
        "      train_input_zutaten.append(entry[0])\n",
        "      train_input_anweisungen.append(entry[1])\n",
        "      \n",
        "  for entry in test_input:\n",
        "      test_input_zutaten.append(entry[0])\n",
        "      test_input_anweisungen.append(entry[1])\n",
        "      \n",
        "  #Als numpy-array\n",
        "  train_label = np.array(train_label)\n",
        "  test_label = np.array(test_label)\n",
        "  train_input_zutaten = np.array(train_input_zutaten)\n",
        "  test_input_zutaten = np.array(test_input_zutaten)\n",
        "\n",
        "  return train_label, test_label, train_input_zutaten, test_input_zutaten,train_input_anweisungen, test_input_anweisungen"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN9ibp9URpDr"
      },
      "source": [
        "train_label, test_label, train_input_zutaten, test_input_zutaten,train_input_anweisungen,test_input_anweisungen = splitData()"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivcbklHNiwj-"
      },
      "source": [
        "def tokenize_directions(train_input_anweisungen, test_input_anweisungen):\n",
        "  #Anweisungen tokenizen und indizieren\n",
        "  tokenizer = Tokenizer(num_words=500)\n",
        "  tokenizer.fit_on_texts(train_input_anweisungen)\n",
        "\n",
        "  train_input_anweisungen = tokenizer.texts_to_sequences(train_input_anweisungen)\n",
        "  test_input_anweisungen = tokenizer.texts_to_sequences(test_input_anweisungen)\n",
        "  \n",
        "  return train_input_anweisungen, test_input_anweisungen, tokenizer"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Ol-77pR-Kf"
      },
      "source": [
        "train_input_anweisungen, test_input_anweisungen, tokenizer = tokenize_directions(train_input_anweisungen, test_input_anweisungen)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J67obXiliwkA"
      },
      "source": [
        "def findMaxLength(lst): \n",
        "    maxList = max(lst, key = lambda i: len(i)) \n",
        "    maxLength = len(maxList) \n",
        "    return maxLength"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Aw-_k1iwkA"
      },
      "source": [
        "#Anweisungen padden\n",
        "MAXLEN = min(MINLEN_DIRECTIONS,max(findMaxLength(train_input_anweisungen),findMaxLength(test_input_anweisungen)))\n",
        "\n",
        "train_input_anweisungen = pad_sequences(train_input_anweisungen, padding = 'post', maxlen = MAXLEN)\n",
        "test_input_anweisungen = pad_sequences(test_input_anweisungen, padding = 'post', maxlen = MAXLEN)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG7wb600iwkB"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01hYqsASsIz"
      },
      "source": [
        "def create_glove_embedding():\r\n",
        "  # Create GloVe Embedding Dictionary\r\n",
        "  embeddings_dictionary = dict()\r\n",
        "  glove_file = open(DATA_PATH + '/glove.6B.100d.txt', encoding = 'utf8')\r\n",
        "\r\n",
        "  for line in glove_file:\r\n",
        "      records = line.split()\r\n",
        "      word = records[0]\r\n",
        "      vector_dimensions = np.asarray(records[1:], dtype='float32')\r\n",
        "      embeddings_dictionary[word] = vector_dimensions\r\n",
        "  glove_file.close()\r\n",
        "\r\n",
        "  # Create Embedding Matrix\r\n",
        "  embedding_matrix = np.zeros((VOCAB_SIZE, 100))\r\n",
        "\r\n",
        "  for word, index in tokenizer.word_index.items():\r\n",
        "      embedding_vector = embeddings_dictionary.get(word)\r\n",
        "      if embedding_vector is not None:\r\n",
        "          embedding_matrix[index] = embedding_vector\r\n",
        "  return embedding_matrix"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNfblEYeiwkC"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  embedding_matrix = create_glove_embedding()"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-QlZIJYiwkC"
      },
      "source": [
        "#Hyperparamter festlegen\n",
        "INPUT_SHAPE_ZUTATEN = len(index_Zutaten)\n",
        "INPUT_SHAPE_ANWEISUNGEN = MAXLEN\n",
        "DROPOUT_RATE = 0.5\n",
        "OUTPUT_SHAPE = len(index_Kategorien)\n",
        "OUTPUT_SHAPE_ZUTATEN = 32\n",
        "OUTPUT_SHAPE_ANWEISUNGEN = 32\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LOSS_FUNCTION = 'categorical_crossentropy'\n",
        "OPTIMIZER = 'adam'"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpVSCGZNiwkC"
      },
      "source": [
        "#Methode zur Erstellung des Zutaten Neuronalen Netzes (MLP)\n",
        "def createZutatenNN(input_shape,p_dropout,output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_shape, activation='relu'))\n",
        "    model.add(Dropout(p_dropout))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(p_dropout))\n",
        "    model.add(Dense(output_shape, activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd7gEJMciwkE"
      },
      "source": [
        "#Methode zur Erstellung des Anweisungen Convolutional Neuronalen Netzes\n",
        "def createAnweisungenNN(input_shape,p_dropout,output_shape):\n",
        "    modelCNN = Sequential()\n",
        "    embedding_layerC = Embedding(VOCAB_SIZE, 100, weights = [embedding_matrix], input_length = input_shape, trainable = False) \n",
        "\n",
        "    modelCNN.add(embedding_layerC)\n",
        "    modelCNN.add(Conv1D(128, 10, activation='relu', input_shape=(None, MAXLEN, 100)))\n",
        "    modelCNN.add(Dropout(p_dropout))\n",
        "    modelCNN.add(MaxPooling1D(pool_size = 4))\n",
        "    modelCNN.add(Conv1D(256, 5, activation='relu'))\n",
        "    modelCNN.add(GlobalMaxPooling1D())\n",
        "    modelCNN.add(Dropout(p_dropout))\n",
        "    modelCNN.add(Dense(output_shape, activation = 'relu'))\n",
        "    \n",
        "    return modelCNN"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnlF_vITTRaD"
      },
      "source": [
        "def createCombinedNN():\r\n",
        "    #Beide Neuronalen Netze erstellen\r\n",
        "    zutatenNN = createZutatenNN(input_shape=INPUT_SHAPE_ZUTATEN,p_dropout=DROPOUT_RATE,output_shape=OUTPUT_SHAPE_ZUTATEN)\r\n",
        "    anweisungenNN = createAnweisungenNN(input_shape=INPUT_SHAPE_ANWEISUNGEN,p_dropout=DROPOUT_RATE,\r\n",
        "                                      output_shape=OUTPUT_SHAPE_ANWEISUNGEN)\r\n",
        "    #Kombiniertes Neuronales Netz erstellen\r\n",
        "    combinedInput = concatenate([zutatenNN.output, anweisungenNN.output])\r\n",
        "    x = Dense(16, activation=\"relu\")(combinedInput)\r\n",
        "    x = Dense(OUTPUT_SHAPE, activation=\"softmax\")(x)\r\n",
        "    model = Model(inputs=[zutatenNN.input, anweisungenNN.input], outputs=x)\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-LunO3Thv0"
      },
      "source": [
        "def create_model(summary=False):\r\n",
        "  if BOTH_NEURAL_NETWORKS:\r\n",
        "    model = createCombinedNN()\r\n",
        "  else:\r\n",
        "    model = createZutatenNN(input_shape=INPUT_SHAPE_ZUTATEN,p_dropout=DROPOUT_RATE,output_shape=OUTPUT_SHAPE)\r\n",
        "   \r\n",
        "  if summary:\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "  model.compile(loss=LOSS_FUNCTION, optimizer=OPTIMIZER,metrics=['accuracy'])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE52COdxTsAn"
      },
      "source": [
        "def fit_model():\r\n",
        "  model = create_model(True)\r\n",
        "  #Model trainieren\r\n",
        "  print('Trainieren auf ' + str(len(train_input_anweisungen)) + \" Datens√§tzen.\")\r\n",
        "  print('Testen auf ' + str(len(test_input_anweisungen)) + \" Datens√§tzen. \\n\" )\r\n",
        "\r\n",
        "  if BOTH_NEURAL_NETWORKS:\r\n",
        "    history = model.fit(x=[train_input_zutaten,train_input_anweisungen], y=train_label,\r\n",
        "          validation_data=([test_input_zutaten,test_input_anweisungen], test_label),\r\n",
        "          epochs=EPOCHS, batch_size=BATCH_SIZE)\r\n",
        "  else:\r\n",
        "    history = model.fit(train_input_zutaten,train_label,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(test_input_zutaten, test_label))\r\n"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubYuslRKiwkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d843045f-b3fc-4b50-f971-2d6fab803505"
      },
      "source": [
        "with tpu_strategy.scope():\r\n",
        "  fit_model()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 128)               137984    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 146,695\n",
            "Trainable params: 146,695\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Trainieren auf 6424 Datens√§tzen.\n",
            "Testen auf 1606 Datens√§tzen. \n",
            "\n",
            "Epoch 1/10\n",
            "201/201 [==============================] - 9s 30ms/step - loss: 1.5472 - accuracy: 0.4520 - val_loss: 1.1154 - val_accuracy: 0.6021\n",
            "Epoch 2/10\n",
            "201/201 [==============================] - 5s 23ms/step - loss: 1.0698 - accuracy: 0.6248 - val_loss: 0.9715 - val_accuracy: 0.6438\n",
            "Epoch 3/10\n",
            " 77/201 [==========>...................] - ETA: 2s - loss: 0.9322 - accuracy: 0.6726"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9yheQ3YZxR"
      },
      "source": [
        "len(train_input_zutaten[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxO66_qPiwkG"
      },
      "source": [
        "def visualize(h):\n",
        "    plt.plot(h.history['accuracy'], color = 'blue')\n",
        "    plt.plot(h.history['val_accuracy'], color = 'red')\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train','test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    print('')\n",
        "\n",
        "    plt.plot(h.history['loss'], color = 'blue')\n",
        "    plt.plot(h.history['val_loss'], color = 'red')\n",
        "\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train','test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpAhWmQeiwkH"
      },
      "source": [
        "visualize(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CN8ZKdWiwkI"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sABxDENSiwkI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}